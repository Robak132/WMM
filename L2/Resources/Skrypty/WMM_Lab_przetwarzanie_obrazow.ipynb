{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dhiczj3ICPmL"
   },
   "source": [
    "# Wstęp do multimediów - przetwarzenie obrazów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OqjeU1bXTFrp"
   },
   "source": [
    "Do realizacji ćwiczeń i zadań laboratoryjnych z zakresu przetwarzania danych obrazowych wykorzystywany jest Python wraz z bibliotekami NumPy, Matplotlib i OpenCV.\n",
    "\n",
    "Pomocne tutoriale OpenCV:\n",
    "[strona główna](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_tutorials.html),\n",
    "[operacje podstawowe](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_core/py_basic_ops/py_basic_ops.html), \n",
    "[operacje arytmetyczne](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_core/py_image_arithmetics/py_image_arithmetics.html), \n",
    "[przetwarzanie obrazów](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_table_of_contents_imgproc/py_table_of_contents_imgproc.html)\n",
    "(m.in.:\n",
    "[zmiana przestrzeni kolorów](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_colorspaces/py_colorspaces.html#converting-colorspaces), \n",
    "[filtracja](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_filtering/py_filtering.html#filtering),\n",
    "[detekcja krawędzi](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_gradients/py_gradients.html),\n",
    "[progowanie](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_thresholding/py_thresholding.html),\n",
    "[operacje morfologiczne](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_morphological_ops/py_morphological_ops.html),\n",
    "[histogramy](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_histograms/py_histogram_begins/py_histogram_begins.html)).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1658,
     "status": "ok",
     "timestamp": 1615284185962,
     "user": {
      "displayName": "Grzegorz Galiński",
      "photoUrl": "",
      "userId": "07677391325184183263"
     },
     "user_tz": -60
    },
    "id": "NwGdgCmSSS2u"
   },
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sztuH9dildyF"
   },
   "source": [
    "# Dostęp do zewnętrznych plików w środowisku Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DJmcNcpsrTrt"
   },
   "source": [
    "Pliki można przechowywać w folderze `sample_data` środowiska uruchomieniowego Colab - trzeba je tam wgrać, mogą zostać usunięte po zakończeniu sesji.\n",
    "\n",
    "Można też zamontować własny dysk Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "sZETBtQBlhPT"
   },
   "outputs": [],
   "source": [
    "##### dane w folderze środowiska uruchomieniowego\n",
    "# data_dir = \"/content/sample_data/\" \n",
    "\n",
    "# ##### dane na Google Drive\n",
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/drive\")\n",
    "# data_dir = \"/content/drive/My Drive/Colab Notebooks/PMUT_cwiczenia/\"\n",
    "\n",
    "##### dane w lokalnym folderze - uruchamianie skrytpu .py w lokalnym środowisku\n",
    "#data_dir = \"./\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t7RpUVdmrcq7"
   },
   "source": [
    "# Wczytanie obrazu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bi5ck3XPWFCX"
   },
   "source": [
    "Tryby wczytywania obrazu:\n",
    "* `cv2.IMREAD_COLOR` - obraz wczytany zostanie jako barwny, zawsze będzie miał trzy składowe (tablica 3D), nawet jeśli jest monochromatyczny;\n",
    "* `cv2.IMREAD_GRAYSCALE` - obraz wczytany zostanie jako monochromatyczny, zawsze będzie miał tylko jedną składową (tablica 2D);\n",
    "* `cv2.IMREAD_UNCHANGED` - obraz wczytany zostanie '*jak jest*', barwny lub monochromatyczny.\n",
    "\n",
    "Obraz zwracany jest jako tablica `numpy.ndarray`, można go przetwarzać jak każdą tablicę NumPy, m.in.:\n",
    "* `image.shape` - wymiary obrazu: `shape[0]` - wysokość (liczba linii), `shape[1]` - szerokość (liczba pikseli w linii), `shape[2]` - liczba składowych (tylko dla obrazów barwnych);\n",
    "* `image.dtype` - typ danych (liczby całkowite, liczby rzeczywiste, itp., np.: `np.uint8`, `np.float32`, `np.float64`);\n",
    "* `image.min()`, `image.max()` - wartość minimalna/maksymalna.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "yL6kxSdWXFW5"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-3-8ae87f456bac>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mimage\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcv2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata_dir\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;34m\"lena_mono.png\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcv2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mIMREAD_UNCHANGED\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\"image, wymiary: {image.shape}, typ danych: {image.dtype}, wartości: {image.min()} - {image.max()}\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'data_dir' is not defined"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(data_dir+\"lena_mono.png\", cv2.IMREAD_UNCHANGED) \n",
    "print(f\"image, wymiary: {image.shape}, typ danych: {image.dtype}, wartości: {image.min()} - {image.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BKnIpl_1aPXA"
   },
   "source": [
    "# Zapis do pliku.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WMfmqh2tr0Vy"
   },
   "source": [
    "Format zostanie automatycznie dobrany na podstawie nazwy pliku wyjściowego.\n",
    "Możliwe jest ustawienie parametrów dodatkowych, zależnych od formatu wyjściowego (np. 'jakość' dla kodera JPEG)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mA43KsyKYmVU"
   },
   "outputs": [],
   "source": [
    "cv2.imwrite(data_dir+\"out_image.png\", image)\n",
    "cv2.imwrite(data_dir+\"out_image.jpg\", image)\n",
    "cv2.imwrite(data_dir+\"out_image_quality50.jpg\", image, (cv2.IMWRITE_JPEG_QUALITY, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z3nHRE0HpSjX"
   },
   "source": [
    "# Wyświetlanie obrazu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jw2ayO7latAW"
   },
   "source": [
    "### Wyświetlanie z wykorzystaniem okna OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6kEhCOmKr-K4"
   },
   "source": [
    "W zależności od typu danych, zakładane są różne przedziały wartości pikseli:\n",
    "* dla danych `uint8` - zakładany przedział wartości to [0, 255];\n",
    "* dla danych `float32`/`float64` - zakładany jest przedział wartości [0, 1], a wartości pikseli są mnożone przez 255 do wyświetlenia.\n",
    "\n",
    "Żeby wyswietlić kilka obrazów, należy oknom nadać inny tytuł/nazwę."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9HMlYdzxbP8z"
   },
   "outputs": [],
   "source": [
    "# cv2.imshow(\"image\", image)\n",
    "# image_float = image.astype(np.float32) \n",
    "# # image_float = image*1.  ### wykorzystanie operacji arytmetycznej do zmiany typu danych\n",
    "# print(f\"image_float, wymiary: {image_float.shape}, typ danych: {image_float.dtype}, wartości: {image_float.min()} - {image_float.max()}\")\n",
    "# \n",
    "# cv2.imshow(\"image float _bad\", image_float)  ### wyświetlony obraz będzie 'biały'\n",
    "# cv2.imshow(\"image float\", image_float/255)   ### przeskalowanie wartości pikseli do przedziału [0, 1] - obraz wyświetlony prawidłowo\n",
    "# \n",
    "# cv2.waitKey(0)           ### oczekiwanie na naciśnięcie klawisza lub zamknięcie okien\n",
    "# cv2.destroyAllWindows()  ### zniszczenie okien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DzQpZyCmGLZs"
   },
   "outputs": [],
   "source": [
    "# def cv_imshow(img, img_title=\"image\"):\n",
    "#     # cv2.namedWindow(img_title, cv2.WINDOW_AUTOSIZE) # cv2.WINDOW_NORMAL\n",
    "#    \n",
    "#     ##### przeskalowanie obrazu z rzeczywistymi wartościami pikseli, żeby jedną funkcją wywietlać obrazy różnych typów\n",
    "#     if (img.dtype == np.float32) or (img.dtype == np.float64):\n",
    "#         img_ = img/255\n",
    "#     else:\n",
    "#         img_ = img\n",
    "#     cv2.imshow(img_title, img_)\n",
    "#     cv2.waitKey(1)  ### oczekiwanie przez bardzo krótki czas - okno się wyświetli, ale program się nie zablokuje, tylko będzie kontynuowany\n",
    "#\n",
    "# cv_imshow(image, \"image\")\n",
    "# cv_imshow(image_float, \"image float\")\n",
    "#\n",
    "# cv2.waitKey(0)           ### na końcu programu - oczekiwanie na reakcję użytkownika\n",
    "# cv2.destroyAllWindows()  ### należy pamiętać o zniszczeniu okien!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ybLPvBMF_8k"
   },
   "source": [
    "**UWAGA:** W środowisku Colab funkcja `cv2.imshow()` została zablokowana, zamiast niej polecane jest użycie funkcji `cv2_imshow()` z pakietu `google.colab.patches`, funkcja ta przyjmuje tylko jeden argument: obraz do wyświetlenia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XJDUlSmcF8Os"
   },
   "outputs": [],
   "source": [
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "cv2_imshow(image)\n",
    "\n",
    "image_float = image.astype(np.float32) \n",
    "# image_float = image*1. ### wykorzystanie operacji arytmetycznej do zmiany typu danych\n",
    "print(f\"image_float, wymiary: {image_float.shape}, typ danych: {image_float.dtype}, wartości: {image_float.min()} - {image_float.max()}\")\n",
    "\n",
    "cv2_imshow(image_float)  ### cv2_imshow wyświetla obrazy z wartościami rzeczywistymi w sposób prawidłowy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LGAp3WBUe6vT"
   },
   "source": [
    "### Wyświetlanie obrazu z wykorzystaniem pakietu `matplotlib.pyplot`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iwq6Z4l0sHEN"
   },
   "source": [
    "Funckja `plt.imshow()` może dokonywać automatycznego skalowania wartości pikseli do pełnego przedziału wartości ('rozciągnięcie histogramu'), aby tego uniknąć należy jawnie podać minimalną i maksymalną wartość.\n",
    "\n",
    "Funkcja `plt.show()` powoduje wyświetlenie wszystkich utworzonych okien i zablokowanie programu do czasu ich zamknięcia; wiele środowisk programistycznych (np. Spyder, PyCharm, Google Colab) potrafi wyświetlać 'okna' `matlplotlib.pyplot` w ramach swojego interfejsu graficznego - wywołanie `plt.show()` nie jest wtedy konieczne w celu wyświetlenia obrazu (może natomiast wymusić jego wyświetlenie w tym momencie), ale też obrazy wyświetlane są z reguły w ograniczonych rozmiarach - do 'dokładnego' ich oglądania warto zapisać je do pliku i otworzyć w 'zewnętrznej' przeglądarce obrazów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x9q9wHMGfEQ8"
   },
   "outputs": [],
   "source": [
    "def plt_imshow(img, img_title=\"image\"):\n",
    "    plt.figure() \n",
    "    plt.title(img_title) \n",
    "    # plt.imshow(img, cmap=\"gray\")  ### możliwe automatyczne skalowanie wartości pikseli\n",
    "    plt.imshow(img, cmap=\"gray\", vmin=0, vmax=255)  ### bez skalowania wartości pikseli\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    plt.show()\n",
    "\n",
    "plt_imshow(image)\n",
    "\n",
    "image_dark = cv2.imread(data_dir+\"lena_mono_dark.png\", cv2.IMREAD_UNCHANGED)\n",
    "print(f\"image_dark, wymiary: {image_dark.shape}, typ danych: {image_dark.dtype}, wartości: {image_dark.min()} - {image_dark.max()}\")\n",
    "plt_imshow(image_dark, \"image_dark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jaKFS9X5g0Bq"
   },
   "source": [
    "### Funkcje pomocnicze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKBks-kasYQX"
   },
   "source": [
    "Pomocnicze funkcje, aby można było łatwo zmieniać sposób wyświetalania obrazów i wypisywania komunikatów bez konieczności modyfikowania dalszych przykładów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 446,
     "status": "ok",
     "timestamp": 1615284307321,
     "user": {
      "displayName": "Grzegorz Galiński",
      "photoUrl": "",
      "userId": "07677391325184183263"
     },
     "user_tz": -60
    },
    "id": "b_OaLucVhGgr"
   },
   "outputs": [],
   "source": [
    "# imshow = cv_imshow   ### wyświetlanie z użyciem cv2\n",
    "# imshow = plt_imshow  ### wyświetlanie z użyciem matplotlib\n",
    "\n",
    "def imshow(img, img_title=\"image\"):  ### 'opakowanie' na cv2_imshow(), żeby 'uzgodnić' parametry wywołania\n",
    "  cv2_imshow(img) \n",
    "\n",
    "def printi(img, img_title=\"image\"):\n",
    "    print(f\"{img_title}, wymiary: {img.shape}, typ danych: {img.dtype}, wartości: {img.min()} - {img.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LCLYX4AiD_C"
   },
   "source": [
    "# Odczytywanie wartości pikseli i ich modyfikacja."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QKOZGGMksjgu"
   },
   "source": [
    "Dane zwracane przez `cv2.imread()` są tablicami pakietu NumPy (`numpy.ndarray`) i można nimi operować jak każdą inną tablicą NumPy.\n",
    "\n",
    "Obowiązuje notacja macierzowa, czyli `[wiersz, kolumna]`. Konstrukcja '`start:end`' w określeniu indeksów do tablicy pozwala na odczyt lub modyfikację całego zakresu wierszy bądź kolumn, włącznie z wierszem/kolumną o indeksie `start`, ale już z wyłączeniem `end`. Można pominąć wartości `start` i/lub `end` - zostaną wtedy zastosowane wartości domyślne (początek danych dla `start` i ich koniec dla `end`), można też podawać wartości ujemne (co oznacza określenie indeksu od końca). Na przykład:\n",
    "* `[0:50, 50:100]` - wiersze od 0 do 49 włącznie, kolumny od 50 do 99 włącznie,\n",
    "* `[:50, 50:]` - wiersze od początku do 49 włącznie, kolumny od 50 do końca,\n",
    "* `[:, 10:-1]` - wszystkie wiersze, kolumny od 10 do przedostatniej (pominięta 1 ostatnia kolumna),\n",
    "* `[:, :]` - wszystkie wiersze i kolumny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gvMQSO1SiWfw"
   },
   "outputs": [],
   "source": [
    "px = image[0, 0]\n",
    "print(f\"px = {px}\")\n",
    "\n",
    "image[0,0] = 255\n",
    "print(f\"img[0,0] = {image[0, 0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L41-eQC1iyjI"
   },
   "outputs": [],
   "source": [
    "# for x in range(50):  ### zmiana wartości pojedynczych pikseli - może być nieefektywna\n",
    "#     for y in range(50):\n",
    "#         image[x,y] = 255\n",
    "\n",
    "image[0:50, 0:50] = 255\n",
    "image[0:25, 0:25] = np.ones((25, 25))*192  ### wymiary tablicy modyfikującej muszą być zgodne z zakresem określonym w tablicy modyfikowanej\n",
    "\n",
    "imshow(image, \"zmienione piksele\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ESzHxV0bjDYQ"
   },
   "source": [
    "Zalecaną metodą dostępu/modyfikacji wartości pojedynczych pikseli jest użycie metod `item()` i `itemset()`.\n",
    "\n",
    "Metody te zawsze operują na wartościach skalarnych, więc w przypadku obrazów barwnych należy oddzielnie odczytywać/modyfikować wartość każdej składowej.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UwUpJk4HjtYE"
   },
   "outputs": [],
   "source": [
    "val = image.item(10, 10)\n",
    "print(f\"val: {val}\")\n",
    "\n",
    "image.itemset((10, 10), 0)\n",
    "image.itemset((10, 11), 0)\n",
    "image.itemset((11, 10), 0)\n",
    "image.itemset((11, 11), 0)\n",
    "\n",
    "imshow(image, \"zmieniony piksel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nkmTvjI4n94C"
   },
   "source": [
    "Porównianie czasu wykonania operacji ustawiającej wartości pikseli dwoma metodami:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Vqsqef0oEoJ"
   },
   "outputs": [],
   "source": [
    "def solaryzacja_m1(img):\n",
    "    t1 = time.time()\n",
    "    solarizedimg_m1 = np.zeros(img.shape, np.uint8)  ### utworzenie 'pustego' obrazu o wymaganych wymiarach\n",
    "    for h in range(0, img.shape[0]):\n",
    "        for w in range(0, img.shape[1]):\n",
    "            if img[h][w] <= 127:\n",
    "                solarizedimg_m1[h][w] = 2*img[h][w]\n",
    "            else:\n",
    "                solarizedimg_m1[h][w] = 2*(255-img[h][w])\n",
    "    # solarizedimg_m1 = np.clip(solarizedimg_m1, 0, 255)\n",
    "    t2 = time.time()\n",
    "    print(f\"czas metody 1: {t2-t1}\")\n",
    "    printi(solarizedimg_m1, \"solarizedimg_m1\")\n",
    "    imshow(solarizedimg_m1, \"solarizedimg_m1\")\n",
    "\n",
    "def solaryzacja_m2(img):\n",
    "    t1 = time.time()\n",
    "    solarizedimg_m2 = np.zeros(img.shape, np.uint8)\n",
    "    for h in range(0, img.shape[0]):\n",
    "        for w in range(0, img.shape[1]):\n",
    "            val = img.item(h,w)\n",
    "            if val <= 127:\n",
    "                solarizedimg_m2.itemset((h, w), 2*val)\n",
    "            else:\n",
    "                solarizedimg_m2.itemset((h, w), 2*(255-val))\n",
    "    # solarizedimg_m2 = np.clip(solarizedimg_m2, 0, 255)\n",
    "    t2 = time.time()\n",
    "    print(f\"czas metody 2: {t2-t1}\")\n",
    "    printi(solarizedimg_m2, \"solarizedimg_m2\")\n",
    "    imshow(solarizedimg_m2, \"solarizedimg_m2\")\n",
    "\n",
    "solaryzacja_m1(image) \n",
    "solaryzacja_m2(image) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMH8qYIMorYf"
   },
   "source": [
    "Do modyfikacji wartości pikseli całego obrazu można wykorzystywać operacje arytmetyczne.\n",
    "\n",
    "**UWAGA:** ze względu na zapis wartości pikseli jako liczb całkowitych `uint8`, bardzo łatwo jest przekroczyć zakres wartości [0, 255], co skutkuje 'zniekształceniem' obrazu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-8IHnaKdq6oY"
   },
   "outputs": [],
   "source": [
    "# result1 = image + np.ones(image.shape, dtype=image.dtype)*32  ### przekroczenie zakresu wartości!\n",
    "result1 = image + 32  ### przekroczenie zakresu wartości!\n",
    "printi(result1, \"image+32\")\n",
    "imshow(result1, \"image+32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iLZwlcoYq_Hf"
   },
   "outputs": [],
   "source": [
    "# result2 = image - np.ones(image.shape, dtype=image.dtype)*32  ### przekroczenie zakresu wartości!\n",
    "result2 = image - 32  ### przekroczenie zakresu wartości!\n",
    "printi(result2, \"image-32\")\n",
    "imshow(result2, \"image-32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMYcajkdtHkY"
   },
   "source": [
    "OpenCV dostarcza funkcje automatycznie obsługujące ograniczenie wartości do poprawnego zakresu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qjFtnNKctOFw"
   },
   "outputs": [],
   "source": [
    "result_add = cv2.add(image, np.ones(image.shape, dtype=image.dtype)*128)  ### -> automatyczne ograniczenie wartości do 255!\n",
    "printi(result_add, \"result_add\")\n",
    "imshow(result_add, \"result_add\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RUP1m7IetiOl"
   },
   "outputs": [],
   "source": [
    "result_subtr = cv2.subtract(image, np.ones(image.shape, dtype=image.dtype)*128)  ### -> automatyczne ograniczenie wartości do 0!!!\n",
    "printi(result_subtr, \"result_subtr\")\n",
    "imshow(result_subtr, \"result_subtr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uck19jHYuSSW"
   },
   "outputs": [],
   "source": [
    "##### blending: res = A*img1 + B*img2 + C\n",
    "result_blend1 = cv2.addWeighted(image, 0.1, np.ones(image.shape, dtype=image.dtype)*128, 0.9, 0)\n",
    "printi(result_blend1, \"result_blend1\")\n",
    "imshow(result_blend1, \"result_blend1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w2FbmC8HuiZs"
   },
   "outputs": [],
   "source": [
    "##### parametrem może być również skalar (wtedy można też po prostu wykorzystać parametr C): \n",
    "result_blend2 = cv2.addWeighted(image, 1, 128, -1, 0)  ### -> image-128\n",
    "# result_blend2 = cv2.addWeighted(image, 1, 0, 0, -128)  ### -> image-128\n",
    "printi(result_blend2, \"result_blend2\")\n",
    "imshow(result_blend2, \"result_blend2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyYKfZRdusKI"
   },
   "source": [
    "# Usuwanie szumu z obrazu (*denoising*, *blurring*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uCgkfzKquxOF"
   },
   "source": [
    "OpenCV dostarcza gotowe funkcje do usuwania szumu:\n",
    "* `cv2.blur()` - filtr uśredniający (liniowy, dolnoprzepustowy),\n",
    "* `cv2.GaussianBlur()` - filtr Gaussa (liniowy, dolnoprzepustowy),\n",
    "* `cv2.medianBlur()` - filtr medianowy (nieliniowy).\n",
    "\n",
    "Rozmiar maski filtru ustalany jest parametrami wywołania funkcji.\n",
    "Ponadto dla filtru Gaussa można okreslić odchylenie standardowe \n",
    "(podanie wartosci `0` oznacza automatyczne wyliczenie wartości na podstawie rozmiaru maski).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hcPBq7xnvmIT"
   },
   "source": [
    "#### Obraz zaszumiony szumem gaussowskim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2PPwyLnQvIeF"
   },
   "outputs": [],
   "source": [
    "image_noise = cv2.imread(data_dir+\"lena_mono_noise.png\", cv2.IMREAD_UNCHANGED) \n",
    "printi(image_noise, \"image_noise\")\n",
    "imshow(image_noise, \"image_noise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HNhRS2i0vX03"
   },
   "outputs": [],
   "source": [
    "blur_img = cv2.blur(image_noise, (3, 3))\n",
    "printi(blur_img, \"blur_img\")\n",
    "imshow(blur_img, \"blur_img\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80-uGAQGvbnZ"
   },
   "outputs": [],
   "source": [
    "gblur_img = cv2.GaussianBlur(image_noise, (5, 5), 0)\n",
    "printi(gblur_img, \"gblur_img\")\n",
    "imshow(gblur_img, \"gblur_img\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GjE4UGPovgF4"
   },
   "outputs": [],
   "source": [
    "median_img = cv2.medianBlur(image_noise, 3) \n",
    "printi(median_img, \"median_img\")\n",
    "imshow(median_img, \"median_img\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUdF2BLxvvrS"
   },
   "source": [
    "#### Obraz zaszumiony szumem impulsowym ('sól i pieprz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iXdT6s6Hvz7F"
   },
   "outputs": [],
   "source": [
    "image_inoise = cv2.imread(data_dir+\"lena_mono_inoise.png\", cv2.IMREAD_UNCHANGED) \n",
    "printi(image_inoise, \"image_inoise\")\n",
    "imshow(image_inoise, \"image_inoise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uJKGX42Ev8RV"
   },
   "outputs": [],
   "source": [
    "blur_imgi = cv2.blur(image_inoise, (3, 3))\n",
    "printi(blur_imgi, \"blur_imgi\")\n",
    "imshow(blur_imgi, \"blur_imgi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SYegB57LwAar"
   },
   "outputs": [],
   "source": [
    "gblur_imgi = cv2.GaussianBlur(image_inoise, (5, 5), 0)\n",
    "printi(gblur_imgi, \"gblur_imgi\")\n",
    "imshow(gblur_imgi, \"gblur_imgi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HWkrnDmwwChh"
   },
   "outputs": [],
   "source": [
    "median_imgi = cv2.medianBlur(image_inoise, 3) \n",
    "printi(median_imgi, \"median_imgi\")\n",
    "imshow(median_imgi, \"median_imgi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fUg41rf3LZBf"
   },
   "source": [
    "#### Obliczenie PSNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9RMwrSc5LhFv"
   },
   "outputs": [],
   "source": [
    "def calcPSNR(img1, img2):\n",
    "  imax = 255.**2  ### zakładana wartość pikseli z przedziału [0, 255]\n",
    "  ##### w różnicy obrazów istotne są wartości ujemne, dlatego img1 konwertowany do typu np.float64 (liczby rzeczywiste) aby nie ograniczać wyniku do przedziału [0, 255]\n",
    "  mse = ((img1.astype(np.float64)-img2)**2).sum()/img1.size  ### img1.size - liczba elementów w img1, ==img1.shape[0]*img1.shape[1] dla obrazów mono, ==img1.shape[0]*img1.shape[1]*img1.shape[2] dla obrazów barwnych\n",
    "  return 10.0*np.log10(imax/mse)\n",
    "\n",
    "image = cv2.imread(data_dir+\"lena_mono.png\", cv2.IMREAD_UNCHANGED)\n",
    "psnr = calcPSNR(image, gblur_img)\n",
    "print(psnr)\n",
    "psnr = calcPSNR(image, gblur_imgi)\n",
    "print(psnr)\n",
    "psnr = calcPSNR(image, median_imgi)\n",
    "print(psnr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y9gaf3PBwNms"
   },
   "source": [
    "# Detekcja krawędzi w obrazie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bw3fM0mowPVQ"
   },
   "source": [
    "OpenCV dostarcza gotowe funkcje do wykrywania krawędzi w obrazie:\n",
    "* `cv2.Sobel()` - bazującą na gradiencie (pierwsza pochodna) wartości pikseli,\n",
    "* `cv2.Laplacian()` - bazującą na laplasjanie (druga pochodna) wartości pikseli.\n",
    "\n",
    "Specyfiką tego typu operacji jest to, że w wyniku moga pojawić się również wartości ujemne, dlatego należy ustalić format danych wynikowych np. na liczby rzeczywiste (np. `cv2.CV_64F` lub `cv2.CV_32F`, co odpowiada `np.float64` i `np.float32` odpowiednio), aby te wartości nie zostały 'zgubione'.\n",
    "\n",
    "Operacja detekcji krawędzi jest bardzo czuła na szum występujący w obrazie (generowanych jest wiele 'mikrokrawędzi'), dlatego czasami warto poddać obraz wcześniejszej operacji wygładzania.\n",
    "\n",
    "**UWAGA:** do wyświetlania obrazów brana jest wartość bezwzględna pikseli (`np.abs()`). Nie należy jednak tego robić w każdej sytuacji, jeśli obraz krawędziowy ma być wykorzystywany później do innych operacji (np. wyostrzania obrazu), to informacja o znaku jest bardzo istotna i nie może zostać utracona czy zmodyfikowana!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NfoA2zuswJeH"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(data_dir+\"lena_mono.png\", cv2.IMREAD_UNCHANGED)\n",
    "# image = cv2.imread(data_dir+\"lena_mono_noise.png\", cv2.IMREAD_UNCHANGED)\n",
    "# image = cv2.imread(data_dir+\"lena_mono_inoise.png\", cv2.IMREAD_UNCHANGED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KLFnNwqixrZm"
   },
   "outputs": [],
   "source": [
    "sobx_img = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)/4  ### gradient w kierunku x - krawędzie pionowe\n",
    "soby_img = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)/4  ### gradient w kierunku y - krawędzie poziome\n",
    "printi(sobx_img, \"sobx_img\")\n",
    "printi(soby_img, \"soby_img\")\n",
    "imshow(np.abs(sobx_img), \"sobx_img\")\n",
    "imshow(np.abs(soby_img), \"soby_img\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OuBzPE46xL97"
   },
   "outputs": [],
   "source": [
    "##### suma gradientów - pełna informacja o krawędziach; wartości pikseli jako liczby rzeczywiste - nie ma niebezpieczeństwa przekroczenia zakresu\n",
    "sob_img = sobx_img + soby_img \n",
    "printi(sob_img, \"sob_img\")\n",
    "imshow(np.abs(sob_img), \"sob_img\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3-kihGhzxbj3"
   },
   "outputs": [],
   "source": [
    "sob_img2 = cv2.Sobel(image, cv2.CV_64F, 1, 1, ksize=3)  ### gradienty w kierunku x i y\n",
    "printi(sob_img2, \"sob_img2\")\n",
    "imshow(np.abs(sob_img2), \"sob_img2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mezw70WfxgZ8"
   },
   "outputs": [],
   "source": [
    "lap_img = cv2.Laplacian(image, cv2.CV_64F) \n",
    "printi(lap_img, \"lap_img\")\n",
    "imshow(np.abs(lap_img), \"lap_img\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qWXaOxbTx7Yv"
   },
   "source": [
    "OpenCV dostarcza również gotową implementację algorytmu Canny'ego detekcji krawędzi, którego rezultatem jest nie 'surowy' obraz gradientowy, lecz wynik wieloetapowego procesu wykrywania i przetwarzania krawędzi w postaci obrazu binarnego, na którym krawędzie oznaczone są białymi pikselami. (Więcej: \n",
    "[opis algorytmu Canny'ego w OpenCV](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_canny/py_canny.html) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DWaof9i0yfdY"
   },
   "outputs": [],
   "source": [
    "canny_img = cv2.Canny(image, 75, 200)\n",
    "printi(canny_img, \"canny_img\")\n",
    "imshow(canny_img, \"canny_img\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BAPqoHj9yraD"
   },
   "source": [
    "# Generyczna filtracja obrazu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ax-PiBCXyuCo"
   },
   "source": [
    "OpenCV dostarcza również generyczną funkcję do liniowej filtracji obrazu filtrem o danej masce: `cv2.filter2D()`.\n",
    "Paremetry tej funkcji pozwalają określić typ danych wyjściowych (np. `cv2.CV_8U` - liczby całkowite z przedziału [0, 255], `cv2.CV_64F`, `cv2.CV_32F` - liczby rzeczywiste 64- lub 32-bitowej precyzji; podanie wartości `-1` oznacza wynik takiego samego typu jak dane w obrazie wejściowym), oraz maskę filtru.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-m9mvFaJzDKI"
   },
   "source": [
    "#### Filtracja filtrem dolnoprzepustowym o rozmiarze 5x5, będącym przybliżeniem filtru Gaussa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iYax85YJzA5V"
   },
   "outputs": [],
   "source": [
    "mask_low = np.array([\n",
    "    [1,  4,  7,  4, 1], \n",
    "    [4, 20, 33, 20, 4], \n",
    "    [7, 33, 55, 33, 7], \n",
    "    [4, 20, 33, 20, 4], \n",
    "    [1,  4,  7,  4, 1]], np.float32)\n",
    "mask_low = mask_low/mask_low.sum()  ### normalizacja maski filtru\n",
    "\n",
    "lowpass_img = cv2.filter2D(image, -1, mask_low)  ### '-1' -> dane wyjściowe w takim samym formacie jak dane wejściowe\n",
    "printi(lowpass_img, \"lowpass_img\")\n",
    "imshow(lowpass_img, \"lowpass_img\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l_gWGa0czPPP"
   },
   "source": [
    "#### Filtracja filtrem górnoprzepustowym - laplasjan w czterech kierunkach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZN2s1YAzT4d"
   },
   "outputs": [],
   "source": [
    "mask_lap = np.array([\n",
    "    [-1, -1, -1], \n",
    "    [-1,  8, -1], \n",
    "    [-1, -1, -1]], np.float32)\n",
    "\n",
    "highpass_img = cv2.filter2D(image, cv2.CV_64F, mask_lap)  ### ustalony format danych wyjściowych na liczby rzeczywiste, ze względu na wartości ujemne w wyniku filtracji górnoprzepustowej\n",
    "printi(highpass_img, \"highpass_img\")\n",
    "imshow(np.abs(highpass_img), \"highpass_img\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Syz-yK-lZrME"
   },
   "source": [
    "# Operacje morfologiczne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TiiYKoqSZuY_"
   },
   "source": [
    "OpenCV dostarcza gotowe funkcje do wykonywania operacji morfologicznych na obrazie:\n",
    "* `cv2.erode()` - erozja,\n",
    "* `cv2.dilate()` - dylacja\n",
    "* `cv2.morphologyEx()` - bardziej złożone operacje, m.in. otwarcie, domknięcie, gradient.\n",
    "\n",
    "Parametry funkcji pozwalają określić jądro (maskę) operacji, nie podanie żadnej oznacza wykorzystanie domyślnej maski o rozmiarach 3x3.\n",
    "\n",
    "Operacje morfologiczne z reguły wykonywane są dla obrazów binarnych. Binaryzacji obrazu monochromatycznego można dokonać prostymi operacjami modyfikacji wartości oraz funkcjami z pakietu NumPy, ale OpenCV dostarcza również gotowe funkcje, pozwalające na progowanie obrazu na różne sposoby (nie w każdym trybie progowania wynikiem będzie obraz binarny): `cv2.threshold()` oraz `cv2.adaptiveThreshold()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w6orDIYUbx7w"
   },
   "outputs": [],
   "source": [
    "binary_img = np.where(image >= 128, np.uint8(255), np.uint8(0))  ### wymuszenie liczb 8-bitowych -> np.uint8()\n",
    "printi(binary_img, \"binary_img\")\n",
    "imshow(binary_img, \"binary_img\")\n",
    "\n",
    "th_val, thresh_img = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY_INV)  ### w niektórych trybach próg jest wyznaczany automatycznie i funkcja zwraca jego wartość\n",
    "printi(thresh_img, \"thresh_img\")\n",
    "imshow(thresh_img, \"thresh_img\")\n",
    "\n",
    "adaptth_img = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 8)  ### przydatne szczegółnie przy \"nierównym\" oświetleniu w obrazie\n",
    "printi(adaptth_img, \"adaptth_img\")\n",
    "imshow(adaptth_img, \"adaptth_img\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P-K7eydhgGRW"
   },
   "outputs": [],
   "source": [
    "erode_img = cv2.erode(thresh_img, None)\n",
    "printi(erode_img, \"erode_img\")\n",
    "imshow(erode_img, \"erode_img\")\n",
    "\n",
    "morph_kernel = np.ones((5, 5), dtype=np.uint8)\n",
    "dilate_img = cv2.dilate(thresh_img, morph_kernel)\n",
    "printi(dilate_img, \"dilate_img\")\n",
    "imshow(dilate_img, \"dilate_img\")\n",
    "\n",
    "open_close_img = cv2.morphologyEx(cv2.morphologyEx(thresh_img, cv2.MORPH_OPEN, None), cv2.MORPH_CLOSE, None)  ### cv2.MORPH_GRADIENT, cv2.MORPH_ERODE, cv2.MORPH_DILATE\n",
    "printi(open_close_img, \"open_close_img\")\n",
    "imshow(open_close_img, \"open_close_img\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Ojsp0mmzf2C"
   },
   "source": [
    "# Wyznaczanie i rysowanie histogramu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oVOd2vlvzk45"
   },
   "source": [
    "W pakiecie `matplotlib.pyplot` jest gotowa funkcja, która obliczy i narysuje histogram: `plt.hist()` (jeśli nie chce się rysować histogramu, a tylko go policzyć, można skorzystać z analogicznej funkcji w pakiecie `numpy`: `np.histogram()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4wcfGReWzj7j"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "hist_plt = plt.hist(image.flatten(), 256, range=[0.0, 255.0])\n",
    "# print(hist_plt[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IjXxgv9mzxXI"
   },
   "source": [
    "OpenCV również dostarcza funkcję do wyznaczenia histogramu (ma być dużo szybsza): `cv2.calcHist()`.\n",
    "\n",
    "`cv2.calcHist()` może wyznaczyć histogram dla wielu obrazów równocześnie, dlatego parametry tej funkcji przekazuje się jako tablice.\n",
    "\n",
    "`cv2.calcHist()` zwraca wynik w postaci tablicy dwuwymiarowej, konwersji na tablicę jednowymiarową można dokonać za pomocą funkcji `np.flatten()`.\n",
    "\n",
    "Ze względu na inny sposób traktowania górnego kresu zakresu zmienności wartości pikseli, zakres wartości dla `cv2.calcHist()` należy okrelić jako [0, 256], aby uzyskać wynik identyczny jak dla `plt.hist()` i zakresu [0, 255].\n",
    "\n",
    "Do narysowania najwygodniej jest wykorzystać również `matplotlib.pyplot`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QKH89J110zcd"
   },
   "outputs": [],
   "source": [
    "hist_cv = cv2.calcHist([image], [0], None, [256], [0, 256])\n",
    "hist_cv = hist_cv.flatten()\n",
    "# print(hist_cv)\n",
    "print(f\"suma różnic wartosci histogramów: {np.abs(hist_cv.flatten()-hist_plt[0]).sum()}\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(hist_cv, color=\"blue\")\n",
    "plt.xlim([0,256])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0L7W0sh1AaS"
   },
   "source": [
    "### Wyrównanie histogramu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZnhY5ARb1G4g"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(data_dir+\"lena_mono.png\", cv2.IMREAD_UNCHANGED)\n",
    "printi(image, \"image\")\n",
    "imshow(image, \"image\")\n",
    "\n",
    "equ_img = cv2.equalizeHist(image)\n",
    "printi(equ_img, \"equ_img\")\n",
    "imshow(equ_img, \"equ_img\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uJ3QcPKE1OUc"
   },
   "outputs": [],
   "source": [
    "image_dark = cv2.imread(data_dir+\"lena_mono_dark.png\", cv2.IMREAD_UNCHANGED)\n",
    "printi(image_dark, \"image_dark\")\n",
    "imshow(image_dark, \"image_dark\")\n",
    "\n",
    "equ_imgdark = cv2.equalizeHist(image_dark)\n",
    "printi(equ_imgdark, \"equ_imgdark\")\n",
    "imshow(equ_imgdark, \"equ_imgdark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0jK6FsvI1WqI"
   },
   "source": [
    "# Obrazy barwne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yreTTihc8M_s"
   },
   "source": [
    "#### Przykłady przedstawionych  wcześniej operacji zastosowanych do obrazu barwnego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WHJI60kb67tS"
   },
   "outputs": [],
   "source": [
    "colimage = cv2.imread(data_dir+\"lena_col.png\") \n",
    "# jesli wyswietlamy obrazy uzywajac matplotlib, nalezy dodac konwersje BGR do RGB poprzez [:,:,::-1], czyli:\n",
    "#colimage = cv2.imread(data_dir+\"lena_col.png\")[:,:,::-1] \n",
    "printi(colimage, \"colimage\")\n",
    "imshow(colimage, \"colimage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gQ_0tQ857rPA"
   },
   "outputs": [],
   "source": [
    "col_neg = 255-colimage  ### negatyw\n",
    "printi(col_neg, \"col_neg\")\n",
    "imshow(col_neg, \"col_neg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-CblkVkA7w2E"
   },
   "outputs": [],
   "source": [
    "col_gblur = cv2.GaussianBlur(colimage, (9, 9), 0)\n",
    "printi(col_gblur, \"col_gblur\")\n",
    "imshow(col_gblur, \"col_gblur\")\n",
    "\n",
    "col_mblur = cv2.medianBlur(colimage, 7)\n",
    "imshow(col_mblur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sbdcZ253706C"
   },
   "outputs": [],
   "source": [
    "col_edgesx = cv2.Sobel(colimage, cv2.CV_64F, 1, 0, ksize=3)/4\n",
    "col_edgesy = cv2.Sobel(colimage, cv2.CV_64F, 0, 1, ksize=3)/4\n",
    "printi(col_edgesx, \"col_edgesx\")\n",
    "printi(col_edgesy, \"col_edgesy\")\n",
    "imshow(col_edgesx, \"col_edgesx\")\n",
    "imshow(col_edgesy, \"col_edgesy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eis93kvaYyDs"
   },
   "outputs": [],
   "source": [
    "col_lapl = cv2.Laplacian(colimage, cv2.CV_64F) \n",
    "printi(col_lapl, \"col_lapl\")\n",
    "imshow(np.abs(col_lapl), \"col_lapl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "12JPXABK8Aps"
   },
   "outputs": [],
   "source": [
    "col_canny = cv2.Canny(colimage, 75, 150)\n",
    "printi(col_canny, \"col_canny\")\n",
    "imshow(col_canny, \"col_canny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rqUSi7UR8Imn"
   },
   "outputs": [],
   "source": [
    "col_lowpass = cv2.filter2D(colimage, -1, mask_low)  #'-1' - dane wyjsciowe w takim samym formacie jak dane wejsciowe\n",
    "printi(col_lowpass, \"col_lowpass\")\n",
    "imshow(col_lowpass, \"col_lowpass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-xFrAl38nEG"
   },
   "source": [
    "## Konwersja przestrzeni kolorów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KsvQXR-i854d"
   },
   "source": [
    "Konwersja z BGR (domyślny format w OpenCV) do HSV.\n",
    "\n",
    "Dostępne są dwa typy konwersji:\n",
    "* `cv2.COLOR_BGR2HSV` - zakres wartości H to [0, 179]\n",
    "* `cv2.COLOR_BGR2HSV_FULL` - zakres wartości H to [0, 255]\n",
    "\n",
    "W pierwszym przypadku, przy samodzielnej modyfikacji wartości H należy zadbać o odpowiednie ich ograniczenie do przedziału [0, 179] (wartość `180` przechodzi w `0`, wartosć `-1` - w `179`) przy jednoczesnym nieprzekroczeniu zakresu [0, 255] (zakres typu `uint8`).\n",
    "\n",
    "W drugim przypadku modyfikacje wartosci H w sposób automatyczny są 'zawijane' w przedziale [0, 255] i mogą być prostsze w zapisie.\n",
    "\n",
    "Dla wartosci S i V obie konwersje sa równoważne.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hFsFjJTi9boX"
   },
   "source": [
    "#### Modyfikacja nasycenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bte4w0019ZrX"
   },
   "outputs": [],
   "source": [
    "col_hsv = cv2.cvtColor(colimage, cv2.COLOR_BGR2HSV)\n",
    "col_hsv[:, :, 1] = cv2.multiply(col_hsv[:, :, 1], 2)\n",
    "col_sat = cv2.cvtColor(col_hsv, cv2.COLOR_HSV2BGR)\n",
    "imshow(col_sat, \"col_sat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQF7pv779lB-"
   },
   "source": [
    "#### Modyfikacja odcienia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wRqzEIZG9pUQ"
   },
   "outputs": [],
   "source": [
    "col_hsv = cv2.cvtColor(colimage, cv2.COLOR_BGR2HSV_FULL)\n",
    "col_hsv[:, :, 0] += 90  ### nie cv2.add() albo podobna, bo nie chcemy 'obcięcia' wartości, a właśnie ich 'zawinięcia'\n",
    "col_hue = cv2.cvtColor(col_hsv, cv2.COLOR_HSV2BGR_FULL)\n",
    "imshow(col_hue, \"col_hue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u000TUPs9wqF"
   },
   "source": [
    "#### Modyfikacja jasności"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fivZXp0x9zWm"
   },
   "outputs": [],
   "source": [
    "col_hsv = cv2.cvtColor(colimage, cv2.COLOR_BGR2HSV)\n",
    "col_hsv[:, :, 2] = cv2.subtract(col_hsv[:, :, 2], 64)  ### a tu właśnie 'obcięcie' jest pożądane\n",
    "col_val = cv2.cvtColor(col_hsv, cv2.COLOR_HSV2BGR)\n",
    "imshow(col_val, \"col_val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FMo7qgUC99Jj"
   },
   "source": [
    "#### Efekt sepii (lub dowolnego innego koloru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_yQIjrU19_Ic"
   },
   "outputs": [],
   "source": [
    "##### można wykorzystać obraz monochromatyczny (jedna składowa) i dokonać jego konwersji na obraz 'barwny' (trzy składowe, wszystkie o takiej samej wartości)\n",
    "# image = cv2.imread(\"lena_mono.png\", cv2.IMREAD_UNCHANGED)\n",
    "# image_gray = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "##### można też obraz monochromatyczny od razu wczytać jako 'barwny' (obraz barwny należy najpierw skonwertować na szaroodcieniowy)\n",
    "image_gray = cv2.imread(data_dir+\"lena_mono.png\", cv2.IMREAD_COLOR) \n",
    "\n",
    "imshow(image_gray, \"image_gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ABf3znVz_JkV"
   },
   "outputs": [],
   "source": [
    "image_hsv = cv2.cvtColor(image_gray, cv2.COLOR_BGR2HSV)\n",
    "image_hsv[:, :, 0] = 25  ### trzeba ustawić odcień...\n",
    "image_hsv[:, :, 1] = 96  ### oraz nasycenie\n",
    "image_col = cv2.cvtColor(image_hsv, cv2.COLOR_HSV2BGR)\n",
    "imshow(image_col, \"image_col\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_k44O4S2_tAi"
   },
   "source": [
    "#### Paleta barw HSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C3RH543i_4KC"
   },
   "outputs": [],
   "source": [
    "def generateHSVCircle(rad):  ### wersja z obliczaniem wartości dla każdego piskela\n",
    "    ##### rad - promień palety\n",
    "    sz = 2*rad+1   ### całkowity rozmiar (szerokość i wysokość) obrazu wynikowego\n",
    "    cx = cy = rad  ### centrum palety w obrazie\n",
    "    \n",
    "    img_hsv = np.zeros((sz, sz, 3), dtype=np.uint8)  ### pusty obraz o pożądanych rozmiarach\n",
    "\n",
    "    for x in range(0, sz, 1):\n",
    "        for y in range(0, sz, 1):\n",
    "            dist = np.sqrt((x-cx)**2 + (y-cy)**2)\n",
    "            if dist > rad: \n",
    "                img_hsv.itemset((y, x, 0), 0)\n",
    "                img_hsv.itemset((y, x, 1), 0)\n",
    "                img_hsv.itemset((y, x, 2), 0)\n",
    "            else:\n",
    "                hue = np.degrees(np.arctan2(cy-y, x-cx))  ### np.arctan() daje wartości [-180, 180]...\n",
    "                hue = np.round(hue/2)%180                 ### ...a potrzebne są [0, 180], dlatego '/2' i '%180' (% 'poprawi' zarówno ujemne, jak i zmieni 180 na 0)\n",
    "                img_hsv.itemset((y, x, 0), hue)                     ### hue: zależnie od kąta, od 0 do 179 (180 to znowu 0)\n",
    "                img_hsv.itemset((y, x, 1), np.round(dist/rad*255))  ### nasycenie: na brzegu max (255), maleje do 0 w środku\n",
    "                img_hsv.itemset((y, x, 2), 255)                     ### value: zawsze max\n",
    "    \n",
    "    return cv2.cvtColor(img_hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "def generateHSVCircle_v2(rad):  ### wersja z obliczeniami na macierzach (szybsza, ale zapis może mniej 'czytelny')\n",
    "    ##### rad - promień palety\n",
    "    sz = 2*rad+1   ### całkowity rozmiar (szerokość i wysokość) obrazu wynikowego\n",
    "    cx = cy = rad  ### centrum palety w obrazie\n",
    "    \n",
    "    img_hsv = np.zeros((sz, sz, 3), dtype=np.uint8)  ### pusty obraz o pożądanych rozmiarach\n",
    "    \n",
    "    xx = np.tile(np.arange(-rad, rad+1, 1), (sz,1))\n",
    "    yy = xx.T\n",
    "    angles = np.degrees(np.arctan2(-yy, xx))  ### np.arctan() daje wartosci [-180, 180]...\n",
    "    dists = np.sqrt(xx**2 + yy**2)\n",
    "\n",
    "    img_hsv[:,:,0] = np.round(angles/2)%180                             ### ...a Hue ma wartości [0, 180], dlatego '/2' i '%180' (% 'poprawi' zarówno wartości ujemne, jak i zmieni 180 na 0)\n",
    "    img_hsv[:,:,1] = np.where(dists > rad, 0, np.round(dists/rad*255))  ### nasycenie: na brzegu max (255), maleje do 0 w środku, poza paletą też 0\n",
    "    img_hsv[:,:,2] = np.where(dists > rad, 0, 255)                      ### value: w palecie zawsze max, poza paletą 0\n",
    "    \n",
    "    return cv2.cvtColor(img_hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "t1 = time.time()\n",
    "hsv_cir = generateHSVCircle_v2(256)\n",
    "t2 = time.time()\n",
    "print(f\"czas: {t2-t1}\")\n",
    "imshow(hsv_cir, \"hsv_cir\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p2Xi1WxkQJWr"
   },
   "source": [
    "## Wyrównanie histogramu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yjMSsQUmRvl8"
   },
   "source": [
    "`cv2.equalizeHist()` wymaga obrazów monochromatycznych (z jedną składową). \n",
    "\n",
    "Wyrównanie histogramu wykonane osobno dla każdej ze składowych RGB obrazu barwnego powoduje '*zniekształcenie*' barw w obrazie. Dla obrazów barwnych operację tę wykonuje się tylko dla składowej opisującej jasność, np. składowej Y w YCrCb/YUV (`cv2.COLOR_BGR2YCrCb` lub `cv2.COLOR_BGR2YUV`) - operacja do samodzielnego wykonania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Agl_H_bQI5J"
   },
   "outputs": [],
   "source": [
    "# equ_img = cv2.equalizeHist(colimage)  ### -> błąd wykonania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i2dWNdOASmMJ"
   },
   "outputs": [],
   "source": [
    "equ_colimg = np.zeros(colimage.shape, dtype=colimage.dtype)  ### 'pusty' obraz wynikowy \n",
    "\n",
    "equ_colimg[:,:,0] = cv2.equalizeHist(colimage[:,:,0])  ### B -> cv2.imread() zwraca obrazy w formacie BGR\n",
    "equ_colimg[:,:,1] = cv2.equalizeHist(colimage[:,:,1])  ### G\n",
    "equ_colimg[:,:,2] = cv2.equalizeHist(colimage[:,:,2])  ### R\n",
    "\n",
    "imshow(equ_colimg, \"equ_colimg\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOud/f95lAuF10Uqv+nLpdw",
   "collapsed_sections": [],
   "name": "WMM_Lab_przetwarzanie_obrazow.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}